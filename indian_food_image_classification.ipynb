{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "indian_food_image_classification",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wor_XlijQGwS"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-3Pcn40pfgC"
      },
      "source": [
        "categories = os.listdir('food20dataset/test_set')\n",
        "img_size = 256\n",
        "def get_data(data_dir):\n",
        "    data = [] \n",
        "    for category in categories: \n",
        "        path = os.path.join(data_dir, category)\n",
        "        class_num = categories.index(category)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img))#[...,::-1] #convert BGR to RGB format\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
        "                data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data)\n",
        "\n",
        "train = get_data('food20dataset/train_set')\n",
        "val = get_data('food20dataset/test_set')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDIEamo18Owh"
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "x_val = []\n",
        "y_val = []\n",
        "\n",
        "for feature, label in train:\n",
        "  x_train.append(feature)\n",
        "  y_train.append(label)\n",
        "\n",
        "for feature, label in val:\n",
        "  x_val.append(feature)\n",
        "  y_val.append(label)\n",
        "\n",
        "# Normalize the data\n",
        "x_train = np.array(x_train) / 255\n",
        "x_val = np.array(x_val) / 255\n",
        "\n",
        "x_train.reshape(-1, img_size, img_size, 1)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_val.reshape(-1, img_size, img_size, 1)\n",
        "y_val = np.array(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJUk481bQ1C_"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(128,3,padding=\"same\", activation=\"relu\", input_shape=(256,256,3)))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256,activation=\"relu\"))\n",
        "model.add(Dense(20, activation=\"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "opt = Adam(lr=0.0001)\n",
        "model.compile(optimizer = opt , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaASMCskSdvR"
      },
      "source": [
        "history = model.fit(x_train,y_train,epochs = 200, validation_data = (x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biZGdtbn1yz4"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "epochs_range = range(200)\r\n",
        "acc = history.history['accuracy']\r\n",
        "val_acc = history.history['val_accuracy']\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,6))\r\n",
        "plt.rc('xtick', labelsize=10)    # fontsize of the tick labels\r\n",
        "plt.rc('ytick', labelsize=10)\r\n",
        "ax1.plot(epochs_range, acc, label='Training Accuracy', c = '#4CAF50', linewidth=4)\r\n",
        "ax1.plot(epochs_range, val_acc, label='Validation Accuracy', c='red', linewidth=4)\r\n",
        "ax1.legend()\r\n",
        "ax1.set_title('Training and Validation Accuracy',fontsize=18)\r\n",
        "ax1.set_ylabel('Accuracy',fontsize=18)\r\n",
        "ax1.set_xlabel('Epoch',fontsize=18)\r\n",
        "\r\n",
        "ax2.plot(epochs_range, loss, label='Training Loss',c = '#4CAF50', linewidth=4)\r\n",
        "ax2.plot(epochs_range, val_loss, label='Validation Loss', c='red', linewidth=4)\r\n",
        "ax2.legend()\r\n",
        "ax2.set_title('Training and Validation Loss',fontsize=18)\r\n",
        "ax2.set_ylabel('Loss',fontsize=18)\r\n",
        "ax2.set_xlabel('Epoch',fontsize=18)\r\n",
        "fig.tight_layout(pad=3.0)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJF9U-tQXS20"
      },
      "source": [
        "predictions = model.predict_classes(x_val)\n",
        "predictions = predictions.reshape(1,-1)[0]\n",
        "print(classification_report(y_val, predictions, target_names = categories))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEkmw8aV6Vgn"
      },
      "source": [
        "cm1 = confusion_matrix(y_val, predictions)\r\n",
        "df_cm = pd.DataFrame(cm1, index = [i for i in categories],\r\n",
        "              columns = [i for i in categories])\r\n",
        "plt.figure(figsize = (10,7))\r\n",
        "sn.heatmap(df_cm, annot=True,cmap=\"RdPu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYgLSeXB5XVI"
      },
      "source": [
        "## Transfer Learning..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2g-hItgVHxY"
      },
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(input_shape = (256, 256, 3), include_top = False, weights = \"imagenet\")\n",
        "base_model.trainable = False\n",
        "model = tf.keras.Sequential([base_model, tf.keras.layers.GlobalAveragePooling2D(), tf.keras.layers.Dropout(0.2), tf.keras.layers.Dense(20, activation=\"softmax\")])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTWKJ6qAVTWI"
      },
      "source": [
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "history1 = model.fit(x_train,y_train,epochs = 200, validation_data = (x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e844Rz1F8N4O"
      },
      "source": [
        "epochs_range = range(200)\r\n",
        "acc1 = history1.history['accuracy']\r\n",
        "val_acc1 = history1.history['val_accuracy']\r\n",
        "loss1 = history1.history['loss']\r\n",
        "val_loss1 = history1.history['val_loss']\r\n",
        "\r\n",
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,6))\r\n",
        "plt.rc('xtick', labelsize=10)\r\n",
        "plt.rc('ytick', labelsize=10)\r\n",
        "ax1.plot(epochs_range, acc, label='CNN Training Accuracy', c = '#4CAF50', linewidth=4)\r\n",
        "ax1.plot(epochs_range, val_acc, label='CNN Validation Accuracy', c='red', linewidth=4)\r\n",
        "ax1.plot(epochs_range, acc1, label='Transfer learning Training Accuracy', c = '#e72866', linewidth=4)\r\n",
        "ax1.plot(epochs_range, val_acc1, label='Transfer learning Validation Accuracy', c='#282ec7', linewidth=4)\r\n",
        "\r\n",
        "ax1.legend()\r\n",
        "ax1.set_title('Training and Validation Accuracy',fontsize=18)\r\n",
        "ax1.set_ylabel('Accuracy',fontsize=18)\r\n",
        "ax1.set_xlabel('Epoch',fontsize=18)\r\n",
        "\r\n",
        "ax2.plot(epochs_range, loss, label='CNN Training Loss',c = '#4CAF50', linewidth=4)\r\n",
        "ax2.plot(epochs_range, val_loss, label='CNN Validation Loss', c='red', linewidth=4)\r\n",
        "ax2.plot(epochs_range, loss1, label='Transfer learning Training Loss',c = '#c72866', linewidth=4)\r\n",
        "ax2.plot(epochs_range, val_loss1, label='Transfer learning Validation Loss', c='#282ec7', linewidth=4)\r\n",
        "\r\n",
        "ax2.legend()\r\n",
        "ax2.set_title('Training and Validation Loss',fontsize=18)\r\n",
        "ax2.set_ylabel('Loss',fontsize=18)\r\n",
        "ax2.set_xlabel('Epoch',fontsize=18)\r\n",
        "fig.tight_layout(pad=3.0)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK36fFtwVpSg"
      },
      "source": [
        "predictions = model.predict_classes(x_val)\n",
        "predictions = predictions.reshape(1,-1)[0]\n",
        "print(classification_report(y_val, predictions, target_names = categories))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHmUZsHlALsq"
      },
      "source": [
        "cm2 = confusion_matrix(y_val, predictions)\r\n",
        "df_cm = pd.DataFrame(cm2, index = [i for i in categories],\r\n",
        "              columns = [i for i in categories])\r\n",
        "plt.figure(figsize = (10,7))\r\n",
        "sn.heatmap(df_cm, annot=True,cmap=\"RdPu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_d40zySXDWP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}